{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tx1_pre_process import *\n",
    "from old_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/ralleking/Downloads/nes_txt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.read().splitlines()\n",
    "        content = [event.rsplit('_', 1) for event in content]\n",
    "        content.append(['END', '0'])\n",
    "    return content\n",
    "\n",
    "def to_one_hot(vocab, event):\n",
    "    one_hot = np.zeros(len(vocab))\n",
    "    index = vocab[event]\n",
    "    one_hot[index] = 1\n",
    "    return one_hot\n",
    "\n",
    "def padded_one_hot_time(vocab, time, pad_len):\n",
    "    one_hot = np.zeros(pad_len+1)\n",
    "    one_hot[time] = 1\n",
    "    return one_hot\n",
    "\n",
    "def from_one_hot(vocab, vector):\n",
    "    ind = np.argmax(vector)\n",
    "    for k, v in vocab.items():\n",
    "        if v == ind:\n",
    "            return k\n",
    "\n",
    "def one_hot_tensor(pred):\n",
    "    one_hot = torch.zeros(pred.shape)\n",
    "    one_hot[:,pred.max(1)[1]] = 1\n",
    "    return one_hot.double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    file = read_file(DATA_PATH + filename)\n",
    "    songs.extend(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(songs, columns=['event', 'time'])\n",
    "df['note_on'] = df.time.apply(lambda x: x.isdigit())\n",
    "df['time'] = pd.to_numeric(df['time'].replace('NOTEOFF',0))\n",
    "df.loc[df.note_on == False, 'event'] = df.event.apply(lambda x: x + '_NOTEOFF')\n",
    "df.loc[df.event == 'END_NOTEOFF', 'event'] = 'END'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "i = 0\n",
    "for item in df['event'].unique():    \n",
    "    vocab[item] = i\n",
    "    i += 1\n",
    "    \n",
    "df['one_hot_x'] = df.event.apply(lambda x: to_one_hot(vocab, x))\n",
    "df['label'] = df.one_hot_x.apply(lambda x: np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get note on data\n",
    "df.loc[df.event == 'WT', 'note_on'] = False\n",
    "dfNote = df.loc[df.note_on == True]\n",
    "dfNote = dfNote[dfNote.time != 0]\n",
    "dfNote['note_class'] = dfNote['time'].apply(lambda x: padded_one_hot_time(vocab, x, 108))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "data2 = dfNote.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe4_x = []\n",
    "data_pipe4_y = []\n",
    "\n",
    "for i in range(0, len(data2)):\n",
    "    x = np.asarray(data2[i,5].tolist())\n",
    "    y = np.asarray(data2[i,1])\n",
    "\n",
    "    x = torch.from_numpy(x).double()\n",
    "    y = torch.from_numpy(y).double()\n",
    "    \n",
    "    data_pipe4_x.append(x)\n",
    "    data_pipe4_y.append(y)\n",
    "    if i>100000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ralleking/miniconda/envs/deepdiva/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totalt number of songs 1069\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "number_of_steps = 20\n",
    "\n",
    "data_pipe1_x = []\n",
    "data_pipe1_y = []\n",
    "\n",
    "data_pipe2_x = []\n",
    "data_pipe2_y = []\n",
    "\n",
    "data_pipe3_x = []\n",
    "data_pipe3_y = []\n",
    "\n",
    "num_songs = 0\n",
    "\n",
    "chunk_size = number_of_steps\n",
    "for i in range(0, len(data)):    \n",
    "    chunk_x = data[start:chunk_size]\n",
    "    chunk_y = data[chunk_size:chunk_size+1]\n",
    "    start = chunk_size + 1\n",
    "    chunk_size = chunk_size + number_of_steps + 1\n",
    "    if np.in1d('END', chunk_x).all():\n",
    "        num_songs +=1\n",
    "        continue\n",
    "    if np.in1d('END', chunk_y).all():\n",
    "        num_songs +=1\n",
    "        continue\n",
    "    \n",
    "    #Add correct columns to correct datapipes\n",
    "    x = chunk_x[:,3].tolist()\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(chunk_y[0,4])\n",
    "    data_pipe1_x.append(torch.from_numpy(x).double())\n",
    "    data_pipe1_y.append(torch.from_numpy(y).double())\n",
    "    \n",
    "    #pipe 2\n",
    "    x2 = chunk_x[:,[1,4]].tolist()\n",
    "    x2 = np.asarray(x2)\n",
    "    y2 = np.asarray(chunk_y[0,1])\n",
    "    data_pipe2_x.append(torch.from_numpy(x2).double())\n",
    "    data_pipe2_y.append(torch.from_numpy(y2).double())\n",
    "\n",
    "    #pipe 3\n",
    "    x3 = np.asarray(data[i,3].tolist())\n",
    "    y3 = data[i,1]\n",
    "    \n",
    "    data_pipe3_x.append(torch.from_numpy(x3).double())\n",
    "    data_pipe3_y.append(torch.from_numpy(np.asarray(y3)).double())\n",
    "    \n",
    "    #For convenience\n",
    "    if i>100000:\n",
    "        break\n",
    "print(\"Totalt number of songs \" + str(num_songs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack(data_pipe1_x)\n",
    "y = torch.stack(data_pipe1_y)\n",
    "x = x.double()\n",
    "y = y.double()\n",
    "\n",
    "x2 = torch.stack(data_pipe2_x)\n",
    "y2 = torch.stack(data_pipe2_y)\n",
    "x2 = x2.double()\n",
    "y2 = y2.double()\n",
    "\n",
    "x3 = torch.stack(data_pipe3_x)\n",
    "y3 = torch.stack(data_pipe3_y)\n",
    "x3 = x3.double()\n",
    "y3 = y3.double()\n",
    "\n",
    "x4 = torch.stack(data_pipe4_x)\n",
    "y4 = torch.stack(data_pipe4_y)\n",
    "x4 = x4.double()\n",
    "y4 = y4.double()\n",
    "\n",
    "\n",
    "data_pipe1 = torch.utils.data.TensorDataset(x, y, x3, y3, x2)\n",
    "data_pipe2 = torch.utils.data.TensorDataset(x4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_pipe1_x\n",
    "del data_pipe1_y\n",
    "\n",
    "del data_pipe2_x\n",
    "del data_pipe2_y \n",
    "\n",
    "del data_pipe3_x \n",
    "del data_pipe3_y\n",
    "\n",
    "del data_pipe4_x \n",
    "del data_pipe4_y\n",
    "\n",
    "del df\n",
    "del dfNote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = torch.zeros(10).double()\n",
    "\n",
    "for _, target, _,_,_ in data_pipe1:\n",
    "    weight1[target.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Has only sequence information. That is x = 10 previous one hot enchodings of sequences, y = the next one\n",
    "batch_size = 200\n",
    "data1 = torch.utils.data.DataLoader(data_pipe1, shuffle=True, batch_size=batch_size)\n",
    "data2 = torch.utils.data.DataLoader(data_pipe2, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #norm\n",
    "        self.normalize = nn.BatchNorm1d(input_size)\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        #x = self.normalize(x)\n",
    "        x = x.view(batch_size, -1, 20)        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = self.sigmoid(out)\n",
    "        out = out.view(batch_size, 10, -1)\n",
    "        out = out[:,-1]\n",
    "\n",
    "        return out, hidden[-1]\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_size, hidden_out):\n",
    "        super(Model2, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_out = hidden_out\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_out)\n",
    "        self.output_layer = nn.Linear(hidden_out, 1)\n",
    "        self.do = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.hidden_dim)\n",
    "        x = self.hidden(x)\n",
    "        x = self.do(x)\n",
    "        x = F.relu(self.output_layer(x))\n",
    "        return x\n",
    "    \n",
    "class Model3(nn.Module):\n",
    "    def __init__(self, input_size, output_size=109, hidden_dim=162):\n",
    "        super(Model3, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.hidden = nn.Linear(input_size, hidden_dim)\n",
    "        self.do = nn.Dropout(0.25)\n",
    "        self.output = nn.Linear(hidden_dim, output_size)\n",
    "        self.do = nn.Dropout(0.25)\n",
    "        \n",
    "        #norm\n",
    "        self.normalize = nn.BatchNorm1d(input_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.normalize(x)\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = F.tanh(self.hidden(x))\n",
    "        x = self.do(x)\n",
    "        x = self.output(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model\n",
    "model = Model(input_size=number_of_steps, output_size=10, hidden_dim=128, n_layers=20)\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.0003\n",
    "w = (1/weight1).to(device)\n",
    "loss1 = nn.CrossEntropyLoss(weight=w)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0dbfed7a4795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel1_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss_ce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/deepdiva/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/deepdiva/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_for_model3 = []\n",
    "model1_loss = []\n",
    "def perpare_for_model3(context, note, time):\n",
    "    time = time.unsqueeze(1)\n",
    "    a = torch.stack((context[-1], note), dim=1)\n",
    "    b = a[a[:, 1, 0] != 1]\n",
    "    #padding = torch.zeros((batch_size-b.shape[0], b.shape[1], b.shape[2])).double().to(device)\n",
    "    #b = torch.cat((b, padding), dim=0)\n",
    "    \n",
    "    time = time[a[:, 1, 0] != 1]\n",
    "    #padding_y = torch.zeros((batch_size-time.shape[0],1)).double().to(device)\n",
    "    #time = torch.cat((time, padding_y), dim=0)\n",
    "    \n",
    "    out = (b.detach(), time.detach())\n",
    "    return out\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for x,y, x3, y3,_ in data1:\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        y3 = y3.to(device)\n",
    "        output, hidden = model(x)\n",
    "        if epoch == n_epochs:\n",
    "            d = perpare_for_model3(hidden, x3, y3)\n",
    "            data_for_model3.append(d)\n",
    "        loss_ce = loss1(output.squeeze(), y.long())\n",
    "        model1_loss.append(loss_ce)\n",
    "        loss_ce.backward()\n",
    "        optimizer.step()\n",
    "    if not epoch%10:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_ce.item()))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight2 = torch.zeros(109).double()\n",
    "\n",
    "for _, target in data_for_model3:\n",
    "    weight2[target.long()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third model (note model)\n",
    "model3 = Model3(20)\n",
    "model3 = model3.to(device)\n",
    "model3 = model3.double()\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.00001\n",
    "loss3 = nn.CrossEntropyLoss(weight=(1/weight2).to(device))\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss_ce3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b6446adb7aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}/{}.............'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_ce3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_ce3' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    for x, y in data_for_model3:\n",
    "        optimizer3.zero_grad() # Clears existing gradients from previous epoch        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model3(x)\n",
    "        loss_ce3 = loss3(output, y.long().squeeze())\n",
    "        loss_ce3.backward()\n",
    "        optimizer3.step()\n",
    "    if not epoch%10:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_ce3.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second model\n",
    "model2 = Model2(20, 1, 10)\n",
    "model2 = model2.to(device)\n",
    "model2 = model2.double()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "lr2=0.1\n",
    "loss2 = nn.MSELoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n",
      "torch.Size([200, 10])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4777cb8951bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def shape_data(from_first_model, x2):\n",
    "    X = torch.cat((from_first_model, x2), dim=1).to(device)\n",
    "    return X\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for x, y, x3, y3,_ in data1:\n",
    "        optimizer2.zero_grad()\n",
    "        x3 = x3.to(device)\n",
    "        y3 = y3.to(device)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        prediction, _ = model(x)\n",
    "        print(prediction.shape)\n",
    "        X = shape_data(prediction, x3)\n",
    "        output = model2(X)\n",
    "        loss_mse = loss2(output, y3)\n",
    "\n",
    "        loss_mse.backward()\n",
    "        optimizer2.step()\n",
    "    if not epoch%10:   \n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take tensor of shape (1x10x10)\n",
    "def predict_seq(sample, model, pred_len, model2, y2, model3, time):\n",
    "    starting_times = list(y2[:,0].squeeze())\n",
    "    notes = sample\n",
    "    model = model.to(device)\n",
    "    sample = sample.to(device)\n",
    "    note = start_note\n",
    "    for i in range(0,pred_len):\n",
    "        prediction = model(sample)[0]\n",
    "        X = shape_data(prediction, note)\n",
    "        time_pred = model2(X)     \n",
    "        prediction = one_hot_tensor(prediction)\n",
    "        \n",
    "        if prediction[0][0] != 1:\n",
    "            input_model3 = perpare_for_model3(context, prediction, time)            \n",
    "            p = model3(input_model3[0])\n",
    "            max_val, max_index = torch.max(p, 1)\n",
    "            starting_times.append(max_index)\n",
    "        else:\n",
    "            starting_times.append(time_pred)\n",
    "\n",
    "        prediction = prediction.view(1,1,10)\n",
    "        notes = torch.cat((notes, prediction), dim=1)\n",
    "        sample = torch.cat((sample, prediction), dim=1)  \n",
    "        sample = sample[:,1:,:]\n",
    "    return notes, starting_times\n",
    "\n",
    "def prediction_to_numpy(predicted_sequence, times):\n",
    "    unpacked_times = [str(int(np.squeeze(time.to(\"cpu\").detach().numpy()))) for time in times]\n",
    "    song = predicted_sequence.to(\"cpu\")\n",
    "    song = song.squeeze()\n",
    "    song = song.numpy()\n",
    "    return song, unpacked_times\n",
    "\n",
    "\n",
    "def numpy_to_txt(song, vocab, times):\n",
    "    i = 0\n",
    "    new_song = []\n",
    "    song = song.tolist()\n",
    "    for event in song:\n",
    "        note = from_one_hot(vocab, event)\n",
    "        note = note + \"_\" + times[i]\n",
    "        new_song.append(note)\n",
    "        i += 1\n",
    "    return new_song\n",
    "\n",
    "def clean_output(txt_song):\n",
    "    clean_song = []\n",
    "    for note in txt_song:\n",
    "        note = note.rsplit('_',1)\n",
    "        if 'OFF' in note[0]:\n",
    "            clean_song.append(note[0])\n",
    "        else:\n",
    "            clean_song.append('_'.join(note))\n",
    "    return clean_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_no = 52\n",
    "\n",
    "data = iter(data1)\n",
    "sample = next(data)\n",
    "\n",
    "x = sample[0][sample_no].view(1,number_of_steps,10).to(device)\n",
    "start_note = sample[2][sample_no].view(1,10).to(device)\n",
    "time = sample[3][sample_no].view(1).to(device)\n",
    "starting_times = sample[4][sample_no].to(device)\n",
    "first_pred, context = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-fe93146bda73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnp_song\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtxt_song\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_to_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_song\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt_song\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtxt_song\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "test, times = predict_seq(x, model, 400, model2, starting_times, model3, time)\n",
    "np_song, times = prediction_to_numpy(test, times)\n",
    "txt_song = numpy_to_txt(np_song, vocab, times)\n",
    "s = clean_output(txt_song)\n",
    "txt_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('s.txt', np.asarray(s), delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
