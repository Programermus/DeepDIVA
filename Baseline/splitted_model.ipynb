{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tx1_pre_process import *\n",
    "from old_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/ralleking/Downloads/nes_txt/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.read().splitlines()\n",
    "        content = [event.rsplit('_', 1) for event in content]\n",
    "        content.append(['END', '0'])\n",
    "    return content\n",
    "\n",
    "def to_one_hot(vocab, event):\n",
    "    one_hot = np.zeros(len(vocab))\n",
    "    index = vocab[event]\n",
    "    one_hot[index] = 1\n",
    "    return one_hot\n",
    "\n",
    "def padded_one_hot_time(vocab, time, pad_len):\n",
    "    one_hot = np.zeros(pad_len+1)\n",
    "    one_hot[time] = 1\n",
    "    return one_hot\n",
    "\n",
    "def from_one_hot(vocab, vector):\n",
    "    ind = np.argmax(vector)\n",
    "    for k, v in vocab.items():\n",
    "        if v == ind:\n",
    "            return k\n",
    "\n",
    "def one_hot_tensor(pred):\n",
    "    one_hot = torch.zeros(pred.shape)\n",
    "    one_hot[:,pred.max(1)[1]] = 1\n",
    "    return one_hot.double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    file = read_file(DATA_PATH + filename)\n",
    "    songs.extend(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(songs, columns=['event', 'time'])\n",
    "df['note_on'] = df.time.apply(lambda x: x.isdigit())\n",
    "df['time'] = pd.to_numeric(df['time'].replace('NOTEOFF',0))\n",
    "df.loc[df.note_on == False, 'event'] = df.event.apply(lambda x: x + '_NOTEOFF')\n",
    "df.loc[df.event == 'END_NOTEOFF', 'event'] = 'END'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "i = 0\n",
    "for item in df['event'].unique():    \n",
    "    vocab[item] = i\n",
    "    i += 1\n",
    "    \n",
    "df['one_hot_x'] = df.event.apply(lambda x: to_one_hot(vocab, x))\n",
    "df['label'] = df.one_hot_x.apply(lambda x: np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get note on data\n",
    "df.loc[df.event == 'WT', 'note_on'] = False\n",
    "dfNote = df.loc[df.note_on == True]\n",
    "dfNote = dfNote[dfNote.time != 0]\n",
    "dfNote['note_class'] = dfNote['time'].apply(lambda x: padded_one_hot_time(vocab, x, 108))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "data2 = dfNote.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe4_x = []\n",
    "data_pipe4_y = []\n",
    "\n",
    "for i in range(0, len(data2)):\n",
    "    x = np.asarray(data2[i,5].tolist())\n",
    "    y = np.asarray(data2[i,1])\n",
    "\n",
    "    x = torch.from_numpy(x).double()\n",
    "    y = torch.from_numpy(y).double()\n",
    "    \n",
    "    data_pipe4_x.append(x)\n",
    "    data_pipe4_y.append(y)\n",
    "    if i>60000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ralleking/miniconda/envs/deepdiva/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totalt number of songs 367\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "chunk_size = 10\n",
    "\n",
    "data_pipe1_x = []\n",
    "data_pipe1_y = []\n",
    "\n",
    "data_pipe2_x = []\n",
    "data_pipe2_y = []\n",
    "\n",
    "data_pipe3_x = []\n",
    "data_pipe3_y = []\n",
    "\n",
    "num_songs = 0\n",
    "for i in range(0, len(data)):    \n",
    "    chunk_x = data[start:chunk_size]\n",
    "    chunk_y = data[chunk_size:chunk_size+1]\n",
    "    start = chunk_size + 1\n",
    "    chunk_size = chunk_size + 11\n",
    "    if np.in1d('END', chunk_x).all():\n",
    "        num_songs +=1\n",
    "        continue\n",
    "    if np.in1d('END', chunk_y).all():\n",
    "        num_songs +=1\n",
    "        continue\n",
    "    \n",
    "    #Add correct columns to correct datapipes\n",
    "    x = chunk_x[:,3].tolist()\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(chunk_y[0,4])\n",
    "    data_pipe1_x.append(torch.from_numpy(x).double())\n",
    "    data_pipe1_y.append(torch.from_numpy(y).double())\n",
    "    \n",
    "    #pipe 2\n",
    "    x2 = chunk_x[:,[1,4]].tolist()\n",
    "    x2 = np.asarray(x2)\n",
    "    y2 = np.asarray(chunk_y[0,1])\n",
    "    data_pipe2_x.append(torch.from_numpy(x2).double())\n",
    "    data_pipe2_y.append(torch.from_numpy(y2).double())\n",
    "\n",
    "    #pipe 3\n",
    "    x3 = np.asarray(data[i,3].tolist())\n",
    "    y3 = data[i,1]\n",
    "    \n",
    "    data_pipe3_x.append(torch.from_numpy(x3).double())\n",
    "    data_pipe3_y.append(torch.from_numpy(np.asarray(y3)).double())\n",
    "    \n",
    "    #For convenience\n",
    "    if i>60000:\n",
    "        break\n",
    "print(\"Totalt number of songs \" + str(num_songs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack(data_pipe1_x)\n",
    "y = torch.stack(data_pipe1_y)\n",
    "x = x.double()\n",
    "y = y.double()\n",
    "\n",
    "x2 = torch.stack(data_pipe2_x)\n",
    "y2 = torch.stack(data_pipe2_y)\n",
    "x2 = x2.double()\n",
    "y2 = y2.double()\n",
    "\n",
    "x3 = torch.stack(data_pipe3_x)\n",
    "y3 = torch.stack(data_pipe3_y)\n",
    "x3 = x3.double()\n",
    "y3 = y3.double()\n",
    "\n",
    "x4 = torch.stack(data_pipe4_x)\n",
    "y4 = torch.stack(data_pipe4_y)\n",
    "x4 = x4.double()\n",
    "y4 = y4.double()\n",
    "\n",
    "\n",
    "data_pipe1 = torch.utils.data.TensorDataset(x, y, x3, y3, x2)\n",
    "data_pipe2 = torch.utils.data.TensorDataset(x4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Has only sequence information. That is x = 10 previous one hot enchodings of sequences, y = the next one\n",
    "batch_size = 200\n",
    "data1 = torch.utils.data.DataLoader(data_pipe1, shuffle=True, batch_size=batch_size)\n",
    "data2 = torch.utils.data.DataLoader(data_pipe2, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        \n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        out = out.view(batch_size, 10, -1)\n",
    "        out = out[:,-1]\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device).double()\n",
    "        return hidden\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_size, hidden_out):\n",
    "        super(Model2, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_out = hidden_out\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.hidden = nn.Linear(hidden_dim, hidden_out)\n",
    "        self.output_layer = nn.Linear(hidden_out, 1)\n",
    "        self.do = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.hidden_dim)\n",
    "        x = self.hidden(x)\n",
    "        x = self.do(x)\n",
    "        x = F.relu(self.output_layer(x))\n",
    "        return x\n",
    "    \n",
    "class Model3(nn.Module):\n",
    "    def __init__(self, input_size, output_size=109, hidden_dim=256):\n",
    "        super(Model3, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.hidden = nn.Linear(input_size, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_size)\n",
    "        self.do = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        x = self.hidden(x)\n",
    "        x = self.do(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first model\n",
    "model = Model(input_size=10, output_size=10, hidden_dim=10, n_layers=10)\n",
    "model = model.to(device)\n",
    "model = model.double()\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.0001\n",
    "\n",
    "loss1 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 1.1255\n",
      "Epoch: 20/100............. Loss: 1.0411\n",
      "Epoch: 30/100............. Loss: 1.1971\n",
      "Epoch: 40/100............. Loss: 0.9888\n",
      "Epoch: 50/100............. Loss: 1.3047\n",
      "Epoch: 60/100............. Loss: 1.1471\n",
      "Epoch: 70/100............. Loss: 0.8749\n",
      "Epoch: 80/100............. Loss: 0.9533\n",
      "Epoch: 90/100............. Loss: 1.1256\n",
      "Epoch: 100/100............. Loss: 0.6912\n"
     ]
    }
   ],
   "source": [
    "data_for_model3 = []\n",
    "\n",
    "def perpare_for_model3(context, note, time):\n",
    "    time = time.unsqueeze(1)\n",
    "    a = torch.stack((context[-1], note), dim=1)\n",
    "    b = a[a[:, 1, 0] != 1]\n",
    "    #padding = torch.zeros((batch_size-b.shape[0], b.shape[1], b.shape[2])).double().to(device)\n",
    "    #b = torch.cat((b, padding), dim=0)\n",
    "    \n",
    "    time = time[a[:, 1, 0] != 1]\n",
    "    #padding_y = torch.zeros((batch_size-time.shape[0],1)).double().to(device)\n",
    "    #time = torch.cat((time, padding_y), dim=0)\n",
    "    \n",
    "    out = (b.detach(), time.detach())\n",
    "    return out\n",
    "\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for x,y, x3, y3,_ in data1:\n",
    "        optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        x3 = x3.to(device)\n",
    "        y3 = y3.to(device)\n",
    "        output, hidden = model(x)\n",
    "        if epoch == n_epochs:\n",
    "            d = perpare_for_model3(hidden, x3, y3)\n",
    "            data_for_model3.append(d)\n",
    "        loss_ce = loss1(output.squeeze(), y.long())\n",
    "        loss_ce.backward()\n",
    "        optimizer.step()\n",
    "    if not epoch%10:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_ce.item()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third model (note model)\n",
    "model3 = Model3(20)\n",
    "model3 = model3.to(device)\n",
    "model3 = model3.double()\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.001\n",
    "\n",
    "loss3 = nn.CrossEntropyLoss()\n",
    "optimizer3 = torch.optim.Adam(model3.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/100............. Loss: 4.5097\n",
      "Epoch: 20/100............. Loss: 4.5288\n",
      "Epoch: 30/100............. Loss: 4.5255\n",
      "Epoch: 40/100............. Loss: 4.5095\n",
      "Epoch: 50/100............. Loss: 4.4915\n",
      "Epoch: 60/100............. Loss: 4.4833\n",
      "Epoch: 70/100............. Loss: 4.4815\n",
      "Epoch: 80/100............. Loss: 4.4740\n",
      "Epoch: 90/100............. Loss: 4.4724\n",
      "Epoch: 100/100............. Loss: 4.4788\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    for x, y in data_for_model3:\n",
    "        optimizer3.zero_grad() # Clears existing gradients from previous epoch        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = model3(x)\n",
    "        loss_ce3 = loss3(output, y.long().squeeze())\n",
    "        loss_ce3.backward()\n",
    "        optimizer3.step()\n",
    "    if not epoch%10:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_ce3.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second model\n",
    "model2 = Model2(20, 1, 10)\n",
    "model2 = model2.to(device)\n",
    "model2 = model2.double()\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "lr2=0.01\n",
    "loss2 = nn.MSELoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1,n_epochs+1):\n",
    "    for x, y, x3, y3,_ in data1:\n",
    "        optimizer2.zero_grad()\n",
    "        x3 = x3.to(device)\n",
    "        y3 = y3.to(device)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        prediction, _ = model(x)\n",
    "        X = shape_data(prediction, x3)\n",
    "        output = model2(X)\n",
    "        loss_mse = loss2(output, y3)\n",
    "\n",
    "        loss_mse.backward()\n",
    "        optimizer2.step()\n",
    "    if not epoch%10:   \n",
    "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
    "        print(\"Loss: {:.4f}\".format(loss_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_data(from_first_model, x2):\n",
    "    X = torch.cat((from_first_model, x2), dim=1).to(device)\n",
    "    return X\n",
    "\n",
    "#take tensor of shape (1x10x10)\n",
    "def predict_seq(sample, model, pred_len, model2, y2, model3, time):\n",
    "    starting_times = list(y2[:,0].squeeze())\n",
    "    notes = sample\n",
    "    model = model.to(device)\n",
    "    sample = sample.to(device)\n",
    "    note = start_note\n",
    "    for i in range(0,pred_len):\n",
    "        prediction = model(sample)[0]\n",
    "        X = shape_data(prediction, note)\n",
    "        \n",
    "        time_pred = model2(X)     \n",
    "        prediction = one_hot_tensor(prediction)\n",
    "        \n",
    "        if prediction[0][0] != 1:\n",
    "            input_model3 = perpare_for_model3(context, prediction, time)            \n",
    "            p = model3(input_model3[0])\n",
    "            max_val, max_index = torch.max(p, 1)\n",
    "            starting_times.append(max_index)\n",
    "        else:\n",
    "            starting_times.append(time_pred)\n",
    "        \n",
    "        prediction = prediction.view(1,1,10)\n",
    "        notes = torch.cat((notes, prediction), dim=1)\n",
    "        sample = torch.cat((sample, prediction), dim=1)  \n",
    "        sample = sample[:,1:,:]\n",
    "    return notes, starting_times\n",
    "\n",
    "def prediction_to_numpy(predicted_sequence, times):\n",
    "    unpacked_times = [str(int(np.squeeze(time.to(\"cpu\").detach().numpy()))) for time in times]\n",
    "    song = predicted_sequence.to(\"cpu\")\n",
    "    song = song.squeeze()\n",
    "    song = song.numpy()\n",
    "    return song, unpacked_times\n",
    "\n",
    "\n",
    "def numpy_to_txt(song, vocab, times):\n",
    "    i = 0\n",
    "    new_song = []\n",
    "    song = song.tolist()\n",
    "    for event in song:\n",
    "        note = from_one_hot(vocab, event)\n",
    "        note = note + \"_\" + times[i]\n",
    "        new_song.append(note)\n",
    "        i += 1\n",
    "    return new_song\n",
    "\n",
    "def clean_output(txt_song):\n",
    "    clean_song = []\n",
    "    for note in txt_song:\n",
    "        note = note.rsplit('_',1)\n",
    "        if 'OFF' in note[0]:\n",
    "            clean_song.append(note[0])\n",
    "        else:\n",
    "            clean_song.append('_'.join(note))\n",
    "    return clean_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_no = 6\n",
    "data = iter(data1)\n",
    "sample = next(data)\n",
    "\n",
    "x = sample[0][sample_no].view(1,10,10).to(device)\n",
    "start_note = sample[2][sample_no].view(1,10).to(device)\n",
    "time = sample[3][sample_no].view(1).to(device)\n",
    "starting_times = sample[4][sample_no].to(device)\n",
    "first_pred, context = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test, times = predict_seq(x, model, 300, model2, starting_times, model3, time)\n",
    "np_song, times = prediction_to_numpy(test, times)\n",
    "txt_song = numpy_to_txt(np_song, vocab, times)\n",
    "s = clean_output(txt_song)\n",
    "txt_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('s.txt', np.asarray(s), delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
